{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<hr>\n",
    "<h1>INF-477. Redes Neuronales Artificiales.</h1>\n",
    "<h2>Tarea 2 - Autoencoders, RBMs y ConvNets</h2>\n",
    "<hr>\n",
    "</center>\n",
    "\n",
    "<div style=\"width:25%; display: inline-block\"></div>\n",
    "<div style=\"width:25%; display: inline-block\">\n",
    "    <b>Juan Carlos Garcés Bernt</b><br>\n",
    "    jcgarces@alumnos.inf.utfsm.cl\n",
    "</div>\n",
    "<div style=\"width:25%; display: inline-block;\">\n",
    "    <b>Natalia Gonzales</b><br>\n",
    "    a@a.cl\n",
    "</div>\n",
    "<div style=\"width:25%; display: inline-block\"></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>1 Entrenamiento de Autoencoders (AEs) y RBMs en MNIST</h1>\n",
    "\n",
    "Como hemos discutido en clases, las RBM's y posteriormente los AE's, fueron un componente crucial en el\n",
    "desarrollo de los modelos que entre 2006 y 2010 vigorizaron el área de las redes neuronales artificiales con\n",
    "logros notables de desempeño en diferentes tareas de aprendizaje automático.<br>\n",
    "En esta sección aprenderemos a utilizar estos modelos en tres escenarios clásicos: reducción de dimensionalidad,\n",
    "denoising y pre-entrenamiento. Con este objetivo en mente, utilizaremos un dataset denominado\n",
    "*MNIST*, bastante conocido en el área e introducido por Yann LeCunn hacia 1998 en un trabajo que,\n",
    "junto al Neocognitron de Fukushima, se considera uno de los principales antecedentes de las redes convolucionales\n",
    "modernas. Se trata de una colección de $70.000$ imágenes de $28 \\times 28$ pixeles correspondientes a\n",
    "dígitos manuscritos (números entre $0$ y $9$). En su versión tradicional, la colección se encuentra separada en\n",
    "dos subconjuntos: uno de entrenamiento de $60.000$ imágenes y otro de test de $10.000$ imágenes. La tarea\n",
    "consiste en entrenar un programa para que aprenda a identificar correctamente el dígito representado en la\n",
    "imagen.\n",
    "<img src=\"img/Fig1.png\">\n",
    "Fig. 1: Dataset MNIST y visualización obtenida usando las primeras dos componentes principales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Escriba una función que cargue los datos desde el repositorio de keras, normalice las imágenes de\n",
    "modo que los pixeles queden en $[0, 1]$, transforme las imágenes en vectores $(\\in \\mathbb{R}^{784})$ y devuelva tres\n",
    "subconjuntos disjuntos: uno de entrenamiento, uno de validación y uno de pruebas. La normalización\n",
    "permite interpretar cada valor como una probabilidad de \"activación\" del un pixel. El conjunto de\n",
    "pruebas será aquel por defecto. Para la construcción del subconjunto de validación su función recibirá\n",
    "un parámetro **NVAL**, cuyo valor por defecto será $1000$. El conjunto de validación se construirá utilizando\n",
    "los últimos **NVAL** casos del conjunto del entrenamiento por defecto. El conjunto de entrenamiento\n",
    "consistirá en las primeras $60000$ - **NVAL** imágenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "x_val = x_train[-nval:]\n",
    "y_val = y_train[-nval:]\n",
    "x_train = x_train[:-nval]\n",
    "y_train = y_train[:-nval]\n",
    "Y_train = np_utils.to_categorical(y_train, 10)\n",
    "Y_val = np_utils.to_categorical(y_val, 10)\n",
    "Y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>1.1 Reducción de Dimensionalidad</h2>\n",
    "Construir una representación de menor dimensionalidad de un objeto en $\\mathbb{R}^d$, consiste en construir una función\u001e",
    " $\\phi: \\mathbb{R}^d \\rightarrow \\mathbb{R}^{d'},$ con $d' \\ll d$ \u001c",
    "que preserve lo mejor posible la \"información\" original. Obtener tal representación es útil desde un punto de vista computacional (compresión) y estadístico (permite construir modelos con un menor número de parámetros libres). Una técnica de reducción de dimensionalidad se denomina *no super-visada* cuando no hace uso de información acerca de las clases a las que pertenecen los datos de entrenamiento, marco de trabajo útil cuando dicha información no está disponible. Un AE y una RBM se pueden considerar métodos no-supervisados de reducción de dimensionalidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Entrene un AR básico (1capa escondida) para generar una representación de MNIST en $d' = 2,8,32,64$ dimensiones. Determine el porcentaje de compresión obtenido y el error de recontrucción en cada caso.\n",
    "¿Mejora el resultado si elegimos una función de activación ReLU para el Encoder? ¿Podría utilizarse una ReLU en el decoder?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "input_img = Input(shape=(784,))\n",
    "encoded = Dense(32, activation='sigmoid')(input_img)\n",
    "decoded = Dense(784, activation='sigmoid')(encoded)\n",
    "autoencoder = Model(input=input_img, output=decoded)\n",
    "encoder = Model(input=input_img, output=encoded)\n",
    "encoded_input = Input(shape=(32,))\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "decoder = Model(input=encoded_input, output=decoder_layer(encoded_input))\n",
    "autoencoder.compile(optimizer=SGD(lr=1.0), loss='binary_crossentropy')\n",
    "autoencoder.fit(x_train,x_train,nb_epoch=50,batch_size=25,shuffle=True,validation_data=(x_val, x_val))\n",
    "autoencoder.save('basic_autoencoder_768x32.h5')\n",
    "#save other stuff ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Para verificar la calidad del modelo obtenido, compare visualmente la recontruscción que logra hacer el autoencoder desde la representación en $\\mathbb{R}^{d'}$ para algunas imágenes del conjunto de pruebas. Determine si la percepción visual se correpsonde con el error de recontrucción observado. Comente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "autoencoder = load_model('basic_autoencoder_768x32.h5')\n",
    "#load other stuff ...\n",
    "encoded_test = encoder.predict(x_test)\n",
    "decoded_test = decoder.predict(encoded_test)\n",
    "import matplotlib\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Para verificar la calidad de la representación obtenida, implemente el siguiente clasificador, denominado *kNN* (k-nearest neighbor): dada una imagen $x$, el clasificador busca las $k=10$ imágenes de entrenamiento más similares $N_{x} = \\{ x^{(k_i)}\\}_{i=1}^{10}$ (de acuerdo a una distancia, e.g. euclidiana) y predice como clase, la etiqueta más popular entre las imágenes $N_x$. Mida el error de pruebas obtenido construyendo este clasificador sobre la data original y luego sobre la data reducida. Compare además los tiempos medios de predicción en ambos escenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encoded_train = encoder.predict(x_train)\n",
    "encoded_test = encoder.predict(x_test)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf = KNeighborsClassifier(10)\n",
    "clf.fit(encoded_train, y_train)\n",
    "clf.fit(encoded_train, y_train)\n",
    "score = clf.score(encoded_test,y_test)\n",
    "print('Classification Accuracy %.2f' % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Para verificar la calidad de la representación obtenida, implemente *k-means* (un método básico de\n",
    "agrupamiento) sobre la representación obtenida por el autoencoder. Mida la calidad del agrupamiento\n",
    "obtenido sobre los datos reducidos utilizando la métrica denominada ARI (*Adjusted Rand Index*) y\n",
    "la función de desempeño (que llamaremos *clustering accuracy*) definida en el código de ejemplo que se\n",
    "proporciona más abajo. Compare el resultado con el agrupamiento obtenido sobre los datos originales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clustering_accuracy(pred_labels,y,nclusters=10):\n",
    "    true_pred = 0.0\n",
    "    for i in range(0,nclusters):\n",
    "        mvlabel = np.argmax(np.bincount(y[pred_labels==i]))\n",
    "        true_pred += sum(y[pred_labels==i] == mvlabel)\n",
    "    return true_pred/len(y)\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "model = KMeans(n_clusters=10)\n",
    "labels_pred = model.fit_predict(encoded_train)\n",
    "score = metrics.adjusted_rand_score(y_train, labels_pred)\n",
    "print ('Clustering ARI %.2f' % score)\n",
    "print ('Clustering ACC %.2f' % clustering_accuracy(labels_pred,y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) $\\star$ Compare la calidad de la representación reducida obtenida por el autoencoder básico con aquella\n",
    "obtenida vía PCA utilizando el mismo número de dimensiones $d'$. Considere los $4$ criterios que hemos\n",
    "utilizado hasta el momento, i.e., error de reconstrucción, visualización de la reconstrucción, desempeño\n",
    "en clasificación (vía kNN) y desempeño en agrupamiento (vía kMeans). Comente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "pca = PCA(n_components=32)\n",
    "pca.fit(x_train)\n",
    "pca_train = pca.transform(x_train)\n",
    "pca_test = pca.transform(x_test)\n",
    "clf = KNeighborsClassifier(10)\n",
    "clf.fit(pca_train, y_train)\n",
    "score = clf.score(pca_test,y_test)\n",
    "print('PCA SCORE %.2f' % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f) Entrene una RBM binaria básica para generar una representación de MNIST en $d' = 2, 8, 32, 64$ dimensiones.\n",
    "Determine el porcentaje de compresión obtenido y el error de reconstrucción en cada caso.\n",
    "Compare con los resultados obtenidos por el autoencoder utilizando los $3$ criterios que hemos utilizado\n",
    "hasta el momento, i.e., error de reconstrucción, desempeño en clasificación (vía kNN) y desempeño en\n",
    "agrupamiento (vía kMeans)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import BernoulliRBM\n",
    "import numpy as np\n",
    "import pickle ##to save trained models\n",
    "model = BernoulliRBM(n_components=32, batch_size=25,learning_rate=0.05,verbose=1, n_iter=50) ##n_components is d\n",
    "model.fit(x_train)##Train using persistent Gibbs chains\n",
    "fileo = open('basicRBM.pickle','wb')\n",
    "pickle.dump(model,fileo)\n",
    "fileo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g) $\\star \\star$ Modifique el autoencoder básico construido en (a) para implementar un *deep autoencoder* (deep\n",
    "AE), es decir, un autoencoder con al menos dos capas ocultas. Demuestre experimentalmente que este\n",
    "autoencoder puede mejorar significativamente la compresión obtenida por PCA utilizando el mismo\n",
    "número de dimensiones $d'$. Experimente con $d' = 2, 4, 8, 16, 32$ y distintas profundidades ($L = 2, 3, 4$).\n",
    "Considere en esta comparación los 3 criterios que hemos utilizado hasta el momento, i.e., error de\n",
    "reconstrucción, desempeño en clasificación (vía kNN) y desempeño en agrupamiento (vía kMeans).\n",
    "Comente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target_dim = 2 #try other and do a nice plot\n",
    "input_img = Input(shape=(784,))\n",
    "encoded1 = Dense(1000, activation='relu')(input_img)\n",
    "encoded2 = Dense(500, activation='relu')(encoded1)\n",
    "encoded3 = Dense(250, activation='relu')(encoded2)\n",
    "encoded4 = Dense(target_dim, activation='relu')(encoded3)\n",
    "decoded4 = Dense(250, activation='relu')(encoded4)\n",
    "decoded3 = Dense(500, activation='relu')(encoded3)\n",
    "decoded2 = Dense(1000, activation='relu')(decoded3)\n",
    "decoded1 = Dense(784, activation='sigmoid')(decoded2)\n",
    "autoencoder = Model(input=input_img, output=decoded1)\n",
    "encoder = Model(input=input_img, output=encoded3)\n",
    "autoencoder.compile(optimizer=SGD(lr=1.0), loss='binary_crossentropy')\n",
    "autoencoder.fit(x_train,x_train,nb_epoch=50,batch_size=25,shuffle=True,validation_data=(x_val, x_val))\n",
    "autoencoder.save('my_autoencoder_768x1000x500x250x2.h5')\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "pca = PCA(n_components=target_dim)\n",
    "pca.fit(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h) Para el caso $d'=2$ de los experimentos anteriores, genere un gráfico que muestre la representación aprendida. Con este fin, utilice por ejemplo la herramienta de visualización TSNE disponible en *sklearn*. Compare cualitativamente el resultado con aquel obtenido usando PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nplot=5000 #warning: mind your memory!\n",
    "encoded_train = encoder.predict(x_train[:nplot])\n",
    "from sklearn.manifold import TSNE\n",
    "model = TSNE(n_components=2, random_state=0)\n",
    "encoded_train = model.fit_transform(encoded_train)\n",
    "\n",
    "colors={0:'b',1:'g',2:'r',3:'c',4:'m',5:'y',6:'k',7:'orange',8:'darkgreen',9:'maroon'}\n",
    "markers={0:'o',1:'+',2:'v',3:'<',4:'>',5:'^',6:'s',7:'p',8:'*',9:'x'}\n",
    "plt.figure(figsize=(10, 10))\n",
    "for idx in xrange(0,nplot):\n",
    "    label = y_train[idx]\n",
    "    line = plt.plot(encoded_train[idx][0], encoded_train[idx][1],color=colors[label], marker=markers[label], markersize=6)\n",
    "pca_train = pca.transform(x_train)\n",
    "encoded_train = pca_train[:nplot]\n",
    "#... plot PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i) Contruya una función que permita visualizar algunos de los pesos aprendidos por las neuronas de la primera capa del autoencoder. Muestre el resultado para las mejores redes conseguidas en los ítem anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "j) Estudie como cambian los resultados del modelo construido en (a) si se impone simetría, es decir, si se trabaja con *tied weights*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>1.2 Denoising </h2>\n",
    "Como hemos discutido en clases, un *denoising autoencoder* (dAE) es esencialmente un *autoencoder* entrenado\n",
    "para reconstruir ejemplos parcialmente corruptos. Varios autores han demostrado que mediante esta modificación simple es posible obtener representaciones latentes más robustas y significativas que aquellas obtenidas por un AE básico. En esta sección exploraremos la aplicación más \"natural\" o \"directa\" del método."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Genere artificialmente una versión corrupta de las imágenes en MNIST utilizando el siguiente modelo de ruido (masking noise): si $x \\in \\mathbb{R}^d$ es una de las imágenes originales, la versión ruidosa $\\tilde x$ se obtiene como $\\tilde x = x \\odot \\xi$ donde $\\odot $ denota el producto de Hadamard ( componente a componente) y $\\xi \\in \\mathbb{R}^d$ es un vector aleatorio binario con componentes Ber($p$) independientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from numpy.random import binomial\n",
    "noise_level = 0.1\n",
    "noise_mask = binomial(n=1,p=noise_level,size=x_train.shape)\n",
    "noisy_x_train = x_train*noise_mask\n",
    "noise_mask = binomial(n=1,p=noise_level,size=x_val.shape)\n",
    "noisy_x_val = x_val*noise_mask\n",
    "noise_mask = binomial(n=1,p=noise_level,size=x_test.shape)\n",
    "noisy_x_test = x_test*noise_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [python35]",
   "language": "python",
   "name": "Python [python35]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
